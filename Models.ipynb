{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('marriage.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset into features and target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:, ['age', 'workclass', 'education_num', 'occupation', 'race', 'capital_gain', 'capital_loss',\n",
    "                'hours_per_week', 'native_country', 'income']]\n",
    "y = df.loc[:, 'marital_status']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list for categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_columns = ['workclass', 'education_num', 'occupation', 'race', 'native_country', 'income']\n",
    "# cont_columns = ['age', 'capital_gain', 'capital_loss', 'hours_per_week']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode each categorical feature separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_encoders = {}\n",
    "# for col in cat_columns:\n",
    "#     print('Encoding {}'.format(col))\n",
    "#     new_LE = LabelEncoder()\n",
    "#     X[col] = new_LE.fit_transform(df[col])\n",
    "#     label_encoders[col] = new_LE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_columns_index = [X.columns.get_loc(col) for col in cat_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # One-hot encode the training data and show the resulting DataFrame with proper column names\n",
    "# ohe = OneHotEncoder(categories=cat_columns, sparse=False, handle_unknown='ignore')\n",
    "\n",
    "# X_np = ohe.fit_transform(df)\n",
    "# # X_train_ohe = ohe.transform(X_train)#.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was from Dan's GoT presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ohe = pd.concat([X[cont_columns], pd.get_dummies(X[cat_columns])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ohe.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get dummy variables for categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies = pd.get_dummies(X, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split (70/30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_dummies, y, test_size=.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale/Normalize data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column Transform continuous features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ColumnTransformer([\n",
    "    ('standardized', StandardScaler(), ['age', 'capital_gain', 'capital_loss', 'hours_per_week'])\n",
    "], remainder='passthrough')\n",
    "\n",
    "Z_train = ct.fit_transform(X_train)\n",
    "Z_test = ct.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model with Multiple Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a collection of classifiers\n",
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Decision Tree\",\n",
    "         \"Random Forest\", \"XGBoost\", \"Neural Net\", \"Logistic Regression\"]\n",
    "\n",
    "classifiers = [\n",
    "#     3 or 5 KNN seem ideal\n",
    "    KNeighborsClassifier(3),\n",
    "#     ['linear', 'poly', 'rbf', 'sigmoid'] all produce similar results\n",
    "    SVC(kernel=\"linear\", C=0.025, random_state=42),\n",
    "    SVC(gamma=2, C=1, random_state=42),\n",
    "    DecisionTreeClassifier(criterion='entropy'),\n",
    "    RandomForestClassifier(criterion='gini', max_depth=5, n_estimators=10, max_features=3, random_state=42),\n",
    "    XGBClassifier(n_estimators=1000, learning_rate=.02, random_state=42),\n",
    "    MLPClassifier(alpha=1, max_iter=1000, random_state=42),\n",
    "    LogisticRegression(solver='liblinear', random_state=42)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untuned classifiers\n",
    "for name, clf in zip(names, classifiers):\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(f'       F1 - {name}: {f1_score(y_test, clf.predict(Z_test)):.2f}')\n",
    "    print(f'Precision - {name}: {precision_score(y_test, clf.predict(Z_test)):.2f}')\n",
    "    print(f'   Recall - {name}: {recall_score(y_test, clf.predict(Z_test)):.2f}')\n",
    "    print(f' Accuracy - {name}: {accuracy_score(y_test, clf.predict(Z_test)):.2f}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_clf = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_neighbors': range(1,5),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['manhattan', 'euclidean', 'minkowski'],\n",
    "    'n_jobs': [-1]\n",
    "}\n",
    "\n",
    "gs_tree = GridSearchCV(KNN_clf, param_grid, cv=3)\n",
    "gs_tree.fit(X_train, y_train)\n",
    "\n",
    "gs_tree.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_clf = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': np.linspace(.1,1,10),\n",
    "    'degree': [2,3,4,5],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "}\n",
    "\n",
    "gs_tree = GridSearchCV(SVC_clf, param_grid, cv=3)\n",
    "gs_tree.fit(X_train, y_train)\n",
    "\n",
    "gs_tree.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree_clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': range(2,20)\n",
    "}\n",
    "\n",
    "gs_tree = GridSearchCV(dtree_clf, param_grid, cv=3)\n",
    "gs_tree.fit(X_train, y_train)\n",
    "\n",
    "gs_tree.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rforest_clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'bootstrap': [True, False],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': range(2,20,2),\n",
    "    'n_estimators': range(10,100,10)\n",
    "}\n",
    "\n",
    "gs_tree = GridSearchCV(rforest_clf, param_grid, cv=3)\n",
    "gs_tree.fit(X_train, y_train)\n",
    "\n",
    "gs_tree.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_clf = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(XGB_clf.get_params().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "   'learning_rate': np.linspace(.3,.7,5),\n",
    "    'n_estimators': range(100,1000,100),\n",
    "    'gamma': [.5,1,1.5,2],\n",
    "    'max_depth': [2,3,4,5,6]\n",
    "    \n",
    "}\n",
    "\n",
    "gs_tree = GridSearchCV(XGB_clf, param_grid, cv=3, verbose=True, n_jobs=-1)\n",
    "gs_tree.fit(X_train, y_train)\n",
    "\n",
    "gs_tree.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_clf = MLPClassifier(max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(MLP_clf.get_params().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'alpha': 10.0**-np.arange(1,10), \n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "    'activation': ['logistic', 'relu', 'tanh'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "}\n",
    "\n",
    "gs_tree = GridSearchCV(MLP_clf, param_grid, cv=3, verbose=True, n_jobs=-1)\n",
    "gs_tree.fit(X_train, y_train)\n",
    "\n",
    "gs_tree.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression ROC/AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.predict(X_test)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = logreg.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: first argument is true values, second argument is predicted probabilities\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.title('ROC curve for marriage classifier')\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
